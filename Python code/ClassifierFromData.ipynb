{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import nltk, re, pprint, random, json\n",
      "\n",
      "def features(feat):\n",
      "    return {\"FriendsCount\": analyze(feat[\"friends_count\"]),\"FollowersCount\": analyze(feat[\"followers_count\"]/100),\n",
      "            \"CreatedAt\": feat[\"created_at\"]}\n",
      "\n",
      "\n",
      "def analyze(data):\n",
      "    if(data<101):\n",
      "        answer=\"0->100\"\n",
      "    if(100<data and data<251):\n",
      "        answer=\"101->250\"\n",
      "    if(250<data and data<501):\n",
      "        answer=\"251->500\"\n",
      "    if(500<data and data<751):\n",
      "        answer=\"501->750\"\n",
      "    if(750<data and data<1001):\n",
      "        answer=\"751->1000\"\n",
      "    if(1000<data and data<2501):\n",
      "        answer=\"1001->2500\"\n",
      "    if(2500<data and data<5001):\n",
      "        answer=\"2501->5000\"\n",
      "    if(5000<data):\n",
      "        answer=\"5000-> Inf\"\n",
      "    return answer\n",
      "\n",
      "import json\n",
      "\n",
      "in_file = open(\"good.json\",\"r\")\n",
      "good = json.load(in_file)\n",
      "in_file.close()\n",
      "\n",
      "in_file2 = open(\"bad.json\",\"r\")\n",
      "bad = json.load(in_file2)\n",
      "in_file2.close()\n",
      "\n",
      "good_bad = len(good[\"users\"])+len(bad[\"users\"]) \n",
      "\n",
      "print \"Number of data: \"+str(good_bad)\n",
      "\n",
      "test_data=([(data,\"good\") for data in good[\"users\"]]+\n",
      "           [(data,\"bad\") for data in bad[\"users\"]])\n",
      "\n",
      "#random.shuffle(test_data)\n",
      "\n",
      "featuresets = [(features(n), g) for (n,g) in test_data]\n",
      "#train_set, test_set = featuresets[int(good_bad/2):], featuresets[:int(good_bad/2)]\n",
      "train_set = featuresets\n",
      "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
      "#print \"Accuracy of classifier: \"+ str(nltk.classify.accuracy(classifier, test_set))\n",
      "classifier.show_most_informative_features(100)\n",
      "#classifier.classify()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of data: 199\n",
        "Most Informative Features\n",
        "               CreatedAt = u'8/2009'        good : bad    =      3.6 : 1.0\n",
        "               CreatedAt = u'11/2012'        bad : good   =      2.4 : 1.0\n",
        "               CreatedAt = u'1/2013'         bad : good   =      2.4 : 1.0\n",
        "               CreatedAt = u'3/2013'        good : bad    =      2.3 : 1.0\n",
        "               CreatedAt = u'10/2013'       good : bad    =      2.3 : 1.0\n",
        "               CreatedAt = u'10/2011'       good : bad    =      2.3 : 1.0\n",
        "               CreatedAt = u'7/2011'        good : bad    =      1.8 : 1.0\n",
        "               CreatedAt = u'4/2009'        good : bad    =      1.8 : 1.0\n",
        "               CreatedAt = u'7/2014'         bad : good   =      1.7 : 1.0\n",
        "               CreatedAt = u'5/2009'         bad : good   =      1.7 : 1.0\n",
        "               CreatedAt = u'10/2014'        bad : good   =      1.7 : 1.0\n",
        "               CreatedAt = u'6/2012'         bad : good   =      1.7 : 1.0\n",
        "               CreatedAt = u'8/2012'         bad : good   =      1.7 : 1.0\n",
        "               CreatedAt = u'11/2011'        bad : good   =      1.7 : 1.0\n",
        "               CreatedAt = u'10/2012'       good : bad    =      1.7 : 1.0\n",
        "               CreatedAt = u'5/2010'        good : bad    =      1.7 : 1.0\n",
        "               CreatedAt = u'2/2013'        good : bad    =      1.7 : 1.0\n",
        "               CreatedAt = u'11/2013'       good : bad    =      1.7 : 1.0\n",
        "               CreatedAt = u'9/2014'        good : bad    =      1.7 : 1.0\n",
        "               CreatedAt = u'1/2010'        good : bad    =      1.7 : 1.0\n",
        "               CreatedAt = u'9/2013'        good : bad    =      1.7 : 1.0\n",
        "            FriendsCount = '501->750'       good : bad    =      1.6 : 1.0\n",
        "            FriendsCount = '1001->2500'     good : bad    =      1.4 : 1.0\n",
        "               CreatedAt = u'5/2011'         bad : good   =      1.4 : 1.0\n",
        "               CreatedAt = u'12/2011'        bad : good   =      1.4 : 1.0\n",
        "               CreatedAt = u'8/2011'         bad : good   =      1.4 : 1.0\n",
        "               CreatedAt = u'1/2012'        good : bad    =      1.4 : 1.0\n",
        "               CreatedAt = u'3/2012'        good : bad    =      1.4 : 1.0\n",
        "               CreatedAt = u'9/2011'        good : bad    =      1.4 : 1.0\n",
        "               CreatedAt = u'3/2011'        good : bad    =      1.4 : 1.0\n",
        "               CreatedAt = u'2/2014'        good : bad    =      1.4 : 1.0\n",
        "               CreatedAt = u'12/2013'       good : bad    =      1.4 : 1.0\n",
        "            FriendsCount = '0->100'          bad : good   =      1.2 : 1.0\n",
        "            FriendsCount = '101->250'        bad : good   =      1.2 : 1.0\n",
        "            FriendsCount = '751->1000'      good : bad    =      1.1 : 1.0\n",
        "            FriendsCount = '251->500'        bad : good   =      1.1 : 1.0\n",
        "          FollowersCount = '0->100'         good : bad    =      1.0 : 1.0\n",
        "               CreatedAt = u'2/2011'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'1/2011'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'7/2010'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'8/2014'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'6/2011'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'10/2010'        bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'7/2012'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'5/2012'         bad : good   =      1.0 : 1.0\n",
        "               CreatedAt = u'9/2010'         bad : good   =      1.0 : 1.0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "from twitter import *\n",
      "import time\n",
      "import json\n",
      "from datetime import datetime\n",
      "\n",
      "CONSUMER_KEY = 'mI7Q6B0aLgQGhdKLR6VlaWy9Y'\n",
      "CONSUMER_SECRET ='IPLDw6vgSnrvvRl9dobYCsUkiXD38iHMMwXERDoXpgTO2qj4XK'\n",
      "OAUTH_TOKEN = '2787613616-ysSGXpAxDtfBLSLepDMuBEQisL5YZunwPs05t89'\n",
      "OAUTH_TOKEN_SECRET = 'KrHgyaTcAeihSyQX7DbCdvc6vc5r6B1PjmgziNUgC1aI9'\n",
      "\n",
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "def createdAt(data):\n",
      "    date = data[\"created_at\"]\n",
      "    thedate = datetime.strptime(date, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
      "    return str(thedate.month)+\"/\"+str(thedate.year)\n",
      "\n",
      "users = open(\"ClassifierPeople.txt\",\"r\")\n",
      "listOfPeople=[]\n",
      "ReFriend = open(\"ReFriend.txt\",\"w\")\n",
      "notReFriend = open(\"notReFriend.txt\",\"w\")\n",
      "\n",
      "for user in users:\n",
      "    listOfPeople.append(user)\n",
      "\n",
      "print \"There was \"+str(len(listOfPeople))+\" people\"\n",
      "listOfPeople=sorted(set(listOfPeople))\n",
      "\n",
      "print \"After sorted there is \"+str(len(listOfPeople))+\" people\"\n",
      "numberOfGood=0\n",
      "data_from_look_up={}\n",
      "while(len(listOfPeople)!=0):\n",
      "    count = 0\n",
      "    users_to_look_up= \"\"\n",
      "    for user in listOfPeople:\n",
      "        if (count<100):\n",
      "            users_to_look_up += user+\",\"\n",
      "            count+=1\n",
      "    listOfPeople=listOfPeople[100:]\n",
      "    data_from_look_up = twitter_api.users.lookup(screen_name=users_to_look_up[0:-1])\n",
      "    for d in data_from_look_up:\n",
      "        if(str(classifier.classify(features({\"friends_count\": d[\"friends_count\"],\"followers_count\": d[\"followers_count\"],\"created_at\": createdAt(d)})))==\"good\"):\n",
      "            ReFriend.write(d[\"screen_name\"]+\"\\n\")\n",
      "            #print d[\"screen_name\"]+\": \"+ str(classifier.classify(features({\"friends_count\": d[\"friends_count\"],\"followers_count\": d[\"followers_count\"],\"created_at\": createdAt(d)})))\n",
      "            numberOfGood+=1\n",
      "        else:\n",
      "            notReFriend.write(d[\"screen_name\"]+\"\\n\")\n",
      "        \n",
      "ReFriend.close()\n",
      "notReFriend.close()\n",
      "print numberOfGood"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There was 600 people\n",
        "After sorted there is 444 people\n",
        "2groovyyyy: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ABC7Jovana: good\n",
        "A_ForeverHart: good\n",
        "Art__c: good\n",
        "Aure_Niall4ever: good\n",
        "AveryGollnick: good\n",
        "BMahan415: good\n",
        "BSTEEZY_: good\n",
        "Banka1996: good\n",
        "BarbaraKlein08: good\n",
        "Boombotix: good\n",
        "Bothie_: good\n",
        "Breannaaa18: good\n",
        "CPVideoMaker: good\n",
        "Champaign_daddy: good\n",
        "ColeGeissinger: good\n",
        "CorryKanzenberg: good\n",
        "DJSTONEE: good\n",
        "Daddy_Station: good\n",
        "Dreamers_Lane: good\n",
        "EmKulers: good\n",
        "EmPess4: good\n",
        "GEORGlAN: good\n",
        "GREAT_EETS: good\n",
        "Gyptsy_pixie: good\n",
        "HannahKonnn: good\n",
        "HarveyCast: good\n",
        "IrishWarriorNYC: good\n",
        "JLisaola: good\n",
        "JMacias21: good\n",
        "Jamiegirl1: good\n",
        "JanetLaCava: good\n",
        "JessicaWhitnee: good\n",
        "JordyDorko: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "JrossBrown: good\n",
        "KarenBoles: good\n",
        "Kassia_peeps_: good\n",
        "KayKayLacuesta: good\n",
        "KellyHook: good\n",
        "KevinTumanyan: good\n",
        "KimmieKness: good\n",
        "LBordalampe: good\n",
        "Leothelionfurry: good\n",
        "LiaRileyWrites: good\n",
        "LosAvina86: good\n",
        "LynetteFrndz: good\n",
        "MSBowden: good\n",
        "ManikRathee: good\n",
        "MapleReam: good\n",
        "Medrannoo: good\n",
        "Meowitsamber: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "MillsBambi: good\n",
        "MissGneva: good\n",
        "Mistress_Harley: good\n",
        "MistyJSGreen: good\n",
        "MobileQATester: good\n",
        "NathalyMorga: good\n",
        "NibblingGypsy: good\n",
        "NinianeK: good\n",
        "Nombe: good\n",
        "OffTheShoulder: good\n",
        "PhotoFilmStage: good\n",
        "Ramsey_EMS: good\n",
        "Realadamkaufman: good\n",
        "ReyesSerrano36: good\n",
        "RossSheingold: good\n",
        "Rowfasho: good\n",
        "SMQattan76: good\n",
        "SantiagoMejia: good\n",
        "SaraRoweRocks: good\n",
        "SaulVillegas45: good\n",
        "Savy_SAVAGE: good\n",
        "SeguraMichele: good\n",
        "SheenaReith: good\n",
        "SidTheeeKid: good\n",
        "Sona_Leto: good\n",
        "SoundsInSilence: good\n",
        "ThatKevinWong: good\n",
        "TheRealDes_xx: good\n",
        "TheRyanxEdge: good\n",
        "Tiffertoes101: good\n",
        "TrEbOrMaC09: good\n",
        "TrojanWarrior: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "VerticalMethod: good\n",
        "WaynesWorld171: good\n",
        "XochitlRojas: good\n",
        "YHAlawadhi: good\n",
        "_Gabsolutely: good\n",
        "_brinasty94: good\n",
        "_loraxxx: good\n",
        "_lunitaaa: good\n",
        "_marriahjade: good\n",
        "_sabrinabiaatch: good\n",
        "a_besaw: good\n",
        "aaalisson: good\n",
        "al_simpkins2: good\n",
        "aldavewebbs: good\n",
        "aloha_maria: good\n",
        "althoughaldoxc: good\n",
        "amberlagorio: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ampontour: good\n",
        "anaisitaaa_: good\n",
        "annievain: good\n",
        "ariannatrading: good\n",
        "aubreyyylayne: good\n",
        "aureusmedjobs: good\n",
        "austingunter: good\n",
        "azure44: good\n",
        "basil_frye21: good\n",
        "blondeblogshell: good\n",
        "boydioro: good\n",
        "capetrovitch: good\n",
        "cashewslover: good\n",
        "cathmking: good\n",
        "catlovesLA: good\n",
        "ceegotcakes: good\n",
        "celinerrrrr: good\n",
        "chelsms: good\n",
        "clubdinein: good\n",
        "cocokonskii: good\n",
        "coleleclaire: good\n",
        "corvetteflex: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "daaarreenn: good\n",
        "deadxboy: good\n",
        "dedward007: good\n",
        "deedeedott: good\n",
        "dramaria: good\n",
        "dseetharaman: good\n",
        "eatteachblog: good\n",
        "eli__ren: good\n",
        "esme_lima: good\n",
        "everyEarthquake: good\n",
        "eyegrooveapp: good\n",
        "flivid_: good\n",
        "gearratio: good\n",
        "gilbertbautist2: good\n",
        "gisseellee_xo: good\n",
        "gnarlyky: good\n",
        "golfdinosaurrr: good\n",
        "grawcie: good\n",
        "gruberyari: good\n",
        "heychelsie: good\n",
        "hollysembera: good\n",
        "iluv5sos: good\n",
        "jackeryinc: good\n",
        "jarjar2k7: good\n",
        "jeffersonwang13: good\n",
        "jess997: good\n",
        "jhoppper23: good\n",
        "john_ivan627: good\n",
        "joycemanners: good\n",
        "juliannakarina: good\n",
        "k3lsey_: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "kaylahopkinsss: good\n",
        "keith_money: good\n",
        "kevinnorman: good\n",
        "kingcokewhite: good\n",
        "kristhaaang: good\n",
        "lang: good\n",
        "launchz: good\n",
        "leetlemegs: good\n",
        "lindsaywasup: good\n",
        "lisalu27: good\n",
        "lissseett: good\n",
        "loganliston: good\n",
        "lostcasualty: good\n",
        "markvalvarez: good\n",
        "mediumwhisper: good\n",
        "meowitsjenny: good\n",
        "meriiii97: good\n",
        "molly_kpen: good\n",
        "morganfarmer_: good\n",
        "mvpkels: good\n",
        "neida_franco: good\n",
        "ngvalentine: good\n",
        "nickballouperez: good\n",
        "nikki_hbk: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nini_marie68: good\n",
        "oceangirl620: good\n",
        "paige_white_: good\n",
        "patrickhealyid: good\n",
        "percipian: good\n",
        "peterrr_spring: good\n",
        "pizzaluvr_69: good\n",
        "privildeged: good\n",
        "rawkwell: good\n",
        "real_eloy: good\n",
        "rebmaeneri: good\n",
        "robertplafker: good\n",
        "rongluzman: good\n",
        "roooosaemu: good\n",
        "savialbright: good\n",
        "shilosarah: good\n",
        "spacecom: good\n",
        "spiritave: good\n",
        "springingleaks: good\n",
        "ssitto: good\n",
        "staircasewit4: good\n",
        "svdxkvt: good"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "svqjournalist: good\n",
        "swissbeatz: good\n",
        "tahoedonner: good\n",
        "tayhowie22: good\n",
        "terrahawk80: good\n",
        "tgeisenheimer: good\n",
        "the___fo_loso: good\n",
        "thenameskatia: good\n",
        "thiaful: good\n",
        "timouthy: good\n",
        "tlrobinson: good\n",
        "torrrayyyyyy: good\n",
        "transmontilyet: good\n",
        "trappfotos: good\n",
        "trishacagatin: good\n",
        "tw: good\n",
        "ughlexiss: good\n",
        "ulirey_23: good\n",
        "undisputed____: good\n",
        "urfriendalberto: good\n",
        "warrenslocum: good\n",
        "wifexruiner: good\n",
        "wildsetfree: good\n",
        "wiretechgirl: good\n",
        "xo_mayraa: good\n",
        "zachagirl: good\n",
        "225\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "from twitter import *\n",
      "import time\n",
      "import json\n",
      "from datetime import datetime\n",
      "\n",
      "CONSUMER_KEY = 'mI7Q6B0aLgQGhdKLR6VlaWy9Y'\n",
      "CONSUMER_SECRET ='IPLDw6vgSnrvvRl9dobYCsUkiXD38iHMMwXERDoXpgTO2qj4XK'\n",
      "OAUTH_TOKEN = '2787613616-ysSGXpAxDtfBLSLepDMuBEQisL5YZunwPs05t89'\n",
      "OAUTH_TOKEN_SECRET = 'KrHgyaTcAeihSyQX7DbCdvc6vc5r6B1PjmgziNUgC1aI9'\n",
      "\n",
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "listOfPeople=[]\n",
      "ReFriend= open(\"notReFriend.txt\",\"r\")\n",
      "for user in ReFriend:\n",
      "    listOfPeople.append(user)\n",
      "\n",
      "data_from_look_up={}\n",
      "numberOfFollowing=0\n",
      "while(len(listOfPeople)!=0):\n",
      "    users_to_look_up= \"\"\n",
      "    count=0\n",
      "    for names in listOfPeople:\n",
      "        if (count<100):\n",
      "            users_to_look_up += names+\",\"\n",
      "            count+=1\n",
      "    listOfPeople=listOfPeople[100:]\n",
      "    data_from_look_up = twitter_api.friendships.lookup(screen_name=users_to_look_up[0:-1],_method=\"GET\")\n",
      "    for d in data_from_look_up:\n",
      "        if 'followed_by' in d[\"connections\"]:\n",
      "            #print d[\"screen_name\"]+\" is following us\"\n",
      "            numberOfFollowing+=1\n",
      "        else:\n",
      "            continue\n",
      "            #print d[\"screen_name\"]+\" is a bastard\"\n",
      "print numberOfFollowing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "29\n"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}